{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11518747,"sourceType":"datasetVersion","datasetId":7224031}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport time\nimport copy\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import models, transforms\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Configuration (Kaggle) ---\nDATA_DIR = '/kaggle/input/dtd-dataset/dtd'  # adjust to your dataset\nIMAGE_DIR = os.path.join(DATA_DIR, 'images')\nLABELS_DIR = os.path.join(DATA_DIR, 'labels')\nOUTPUT_DIR = '/kaggle/working'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T18:49:55.121550Z","iopub.execute_input":"2025-04-22T18:49:55.122147Z","iopub.status.idle":"2025-04-22T18:49:55.126426Z","shell.execute_reply.started":"2025-04-22T18:49:55.122124Z","shell.execute_reply":"2025-04-22T18:49:55.125523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use splits 1-5\nSPLITS = list(range(1, 6))\nMODEL_NAME = 'resnet50'\nNUM_CLASSES = 47\nBATCH_SIZE = 16\nNUM_EPOCHS = 40\nLEARNING_RATE = 5e-4\nWEIGHT_DECAY = 1e-2\nSTEP_LR_SIZE = 12\nSTEP_LR_GAMMA = 0.1\nNUM_WORKERS = 2\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {DEVICE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T18:50:27.768173Z","iopub.execute_input":"2025-04-22T18:50:27.768536Z","iopub.status.idle":"2025-04-22T18:50:27.773500Z","shell.execute_reply.started":"2025-04-22T18:50:27.768514Z","shell.execute_reply":"2025-04-22T18:50:27.772574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Dataset Definition ---\nclass DTDDataset(Dataset):\n    def __init__(self, image_dir, label_files, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.class_names = sorted(os.listdir(image_dir))\n        self.class_to_idx = {c: i for i, c in enumerate(self.class_names)}\n        seen = set()\n        for lf in label_files:\n            with open(lf) as f:\n                for line in f:\n                    path = line.strip()\n                    full = os.path.join(image_dir, path)\n                    if os.path.exists(full) and full not in seen:\n                        seen.add(full)\n                        self.image_paths.append(full)\n                        cls = path.split('/')[0]\n                        self.labels.append(self.class_to_idx[cls])\n\n    def __len__(self): return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert('RGB')\n        if self.transform: img = self.transform(img)\n        lbl = self.labels[idx]\n        return img, lbl\n\n# --- Data Transforms ---\nweights = models.ResNet50_Weights.DEFAULT\ninput_size = weights.transforms().crop_size[0]\nresize_size = weights.transforms().resize_size[0]\nmean, std = weights.transforms().mean, weights.transforms().std\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(input_size),\n        transforms.RandomHorizontalFlip(),\n        transforms.TrivialAugmentWide(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(resize_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(resize_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n}\n\n# --- Prepare DataLoaders ---\ndef get_label_files(split):\n    return [os.path.join(LABELS_DIR, f\"{split}{i}.txt\") for i in SPLITS]\n\ntrain = DTDDataset(IMAGE_DIR, get_label_files('train'), data_transforms['train'])\nval   = DTDDataset(IMAGE_DIR, get_label_files('val'),   data_transforms['val'])\ntest  = DTDDataset(IMAGE_DIR, get_label_files('test'),  data_transforms['test'])\n\ndataloaders = {\n    'train': DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True),\n    'val':   DataLoader(val,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True),\n    'test':  DataLoader(test,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n}\nsizes = {x: len(dataloaders[x].dataset) for x in dataloaders}\nprint(f\"Dataset sizes: {sizes}\")\n\n# --- Model Setup ---\nmodel = getattr(models, MODEL_NAME)(weights=weights)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, NUM_CLASSES)\nmodel = model.to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=STEP_LR_SIZE, gamma=STEP_LR_GAMMA)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T18:51:30.561543Z","iopub.execute_input":"2025-04-22T18:51:30.562230Z","iopub.status.idle":"2025-04-22T18:51:33.470397Z","shell.execute_reply.started":"2025-04-22T18:51:30.562207Z","shell.execute_reply":"2025-04-22T18:51:33.469484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Training Loop ---\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS):\n    best_acc, best_wts = 0, None\n    history = {'train_acc':[], 'val_acc':[], 'train_loss':[], 'val_loss':[]}\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        for phase in ['train','val']:\n            model.train() if phase=='train' else model.eval()\n            running_loss, running_corrects = 0,0\n            for inputs, labels in dataloaders[phase]:\n                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase=='train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                    preds = outputs.argmax(dim=1)\n                    if phase=='train': loss.backward(); optimizer.step()\n                running_loss += loss.item()*inputs.size(0)\n                running_corrects += (preds==labels).sum().item()\n            if phase=='train': scheduler.step()\n            epoch_loss = running_loss/sizes[phase]\n            epoch_acc = running_corrects/sizes[phase]\n            history[f'{phase}_loss'].append(epoch_loss)\n            history[f'{phase}_acc'].append(epoch_acc)\n            print(f\" {phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n            if phase=='val' and epoch_acc>best_acc:\n                best_acc, best_wts = epoch_acc, copy.deepcopy(model.state_dict())\n                torch.save(best_wts, os.path.join(OUTPUT_DIR, 'best_model.pth'))\n                print(f\"  --> New best val acc: {best_acc:.4f}\")\n    model.load_state_dict(best_wts)\n    return model, history\n\nmodel, history = train_model(model, criterion, optimizer, scheduler)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T18:51:55.146290Z","iopub.execute_input":"2025-04-22T18:51:55.146664Z","iopub.status.idle":"2025-04-22T19:42:14.075333Z","shell.execute_reply.started":"2025-04-22T18:51:55.146641Z","shell.execute_reply":"2025-04-22T19:42:14.074519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Testing ---\ndef test_model(model):\n    model.eval(); running_corrects, total=0,0\n    with torch.no_grad():\n        for inputs, labels in dataloaders['test']:\n            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n            outputs = model(inputs)\n            preds = outputs.argmax(dim=1)\n            running_corrects += (preds==labels).sum().item()\n            total += inputs.size(0)\n    acc = running_corrects/total if total>0 else 0\n    print(f\"Test Accuracy: {acc:.4f}\")\n    return acc\n\ntest_acc = test_model(model)\n\n# Optional: save training history\nimport json\nwith open(os.path.join(OUTPUT_DIR, 'history.json'), 'w') as f:\n    json.dump(history, f)\n\nprint(\"Done.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T19:43:31.908837Z","iopub.execute_input":"2025-04-22T19:43:31.909382Z","iopub.status.idle":"2025-04-22T19:43:50.951599Z","shell.execute_reply.started":"2025-04-22T19:43:31.909355Z","shell.execute_reply":"2025-04-22T19:43:50.950900Z"}},"outputs":[],"execution_count":null}]}